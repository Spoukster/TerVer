{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "Даны значения величины заработной платы заемщиков банка (salary) и значения их поведенческого кредитного скоринга (scoring):\n",
    "\n",
    "salary = [35, 45, 190, 200, 40, 70, 54, 150, 120, 110]\n",
    "\n",
    "scoring = [401, 574, 874, 919, 459, 739, 653, 902, 746, 832]\n",
    "\n",
    "Возьмём в качестве признака значение salary, а в качестве целевой переменной - scoring.\n",
    "1. Найдите коэффициенты линейной регрессии с помощью формул для парной регрессии, а затем с помощью метода наименьших квадратов.\n",
    "2. Постройте scatter plot по данным и отметьте на нём прямую линейной регрессии, полученную в п. 1.\n",
    "3. Посчитайте коэффициент детерминации, среднюю ошибку аппроксимации.\n",
    "4. Оцените построенное уравнение регрессии с помощью F-критерия Фишера.\n",
    "5. Постройте для коэффициентов регрессии доверительные интервалы с помощью t-статистики Стьюдента.\n",
    "\n",
    "### Решение\n",
    "1. Частный случай линейной регресси - это парная регрессия. Ее формула выглядит следующм образом: $y = b_0 + b_1 x_1$. А коэффициенты находятся следующим образом: $$b_1 = \\frac{\\overline{yx} - \\overline{y} \\cdot {\\overline{x}}}{\\overline{x^2} - (\\overline{x})^2}, \\:\\: b_0 = \\overline{y} - b_1 \\cdot {\\overline{x}}.$$\n",
    "Найдем коэффициенты линейной регрессии по этим формулам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444.1773573243596, 2.620538882402765)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])\n",
    "y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])\n",
    "\n",
    "b1 = (np.mean(x * y) - np.mean(x) * np.mean(y)) / (np.mean(x ** 2) - np.mean(x) ** 2)\n",
    "b0 = np.mean(y) - b1 * np.mean(x)\n",
    "b0, b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем коэффициенты линейной регрессии методом наименьших квадратов.\n",
    "Для этого составим матрицу признаков, добавив туда столбец со значением 1 и индексом 0. Затем посчитаем коэффициенты по формуле $b = (X^\\top X)^{-1} X^\\top y.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  35.],\n",
       "       [  1.,  45.],\n",
       "       [  1., 190.],\n",
       "       [  1., 200.],\n",
       "       [  1.,  40.],\n",
       "       [  1.,  70.],\n",
       "       [  1.,  54.],\n",
       "       [  1., 150.],\n",
       "       [  1., 120.],\n",
       "       [  1., 110.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.ones((x.shape[0], 1))\n",
    "x_sqr = np.hstack((ones, x.reshape(-1, 1)))\n",
    "x_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[401],\n",
       "       [574],\n",
       "       [874],\n",
       "       [919],\n",
       "       [459],\n",
       "       [739],\n",
       "       [653],\n",
       "       [902],\n",
       "       [746],\n",
       "       [832]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sqr = y.reshape(-1, 1)\n",
    "y_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем определитель матрицы $X^\\top X$ что бы посмотреть насколько он близок к нулю чтобы избежать неустойчивости при вычислении обратной матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349464.00000000023"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTX = x_sqr.T.dot(x_sqr)\n",
    "\n",
    "np.linalg.det(XTX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определитель намного больше 0. Запишем аналитическое решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[444.17735732],\n",
       "       [  2.62053888]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "b = XTX_inv.dot(x_sqr.T).dot(y_sqr)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты линейной регрессии, посчитанные двумя способами, равны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Построим график линейной регрессии и отметим исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'scoring')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3xU9bnv8c8jIMRrlJsQQFAxVmstNrW2tqCiRbAVqlVQtyJSsRYvbV9SRXv2sa1VkN70WLUobsVaL1gEthXB4q3HFtsgavTYVGRTTIKCSvBCuD/nj7VmMkMmYRKyZs1kvu/Xa14z88yazMPq1O+s2+9n7o6IiAjAHnE3ICIi+UOhICIiSQoFERFJUiiIiEiSQkFERJI6x93A7ujRo4cPHDgw7jZERArKsmXL3nf3npleK+hQGDhwIJWVlXG3ISJSUMzs3829pt1HIiKSpFAQEZEkhYKIiCQpFEREJEmhICIiSQoFERFJUiiIiEiSQkFEpJCsWweLF8OmTZH8+YK+eE1EpGisXQt33NH4/KijoKys3T9GoSAiks/efRfuuiu9NnZsJIEACgURkfy0Zg387nfptXPPhfLySD9WoSAikk9qa+Huu9Nr558Pgwfn5OMVCiIi+aCmBu65J712wQVw6KE5bUOhICISp9Wr4d5702vjx8OgQbG0o1AQEYnDqlVw333ptQkT4OCD4+gmSaEgIpJLK1fC7NnptYsvhgED4ulnJwoFEZFcePtteOCB9Np3vgP9+sXTTzMUCiIiUXrrLXjwwfTapEnQt288/eyCQkFEJArV1fDQQ+m1Sy+FPn3i6SdLCgURkfb05pvwyCPptcsug9694+mnlRQKIiLt4Y03YM6c9Nr3vge9esXTTxspFEREdkdVFfzxj+m1yy+HHj3i6Wc3KRRERNri1Vfh8cfTa1dcAd27R/qx85bXMmNRNXX1DfQtLWHKiHLGDGm/wfEUCiIirfHyy7BgQXrtqqvggAMi/+h5y2uZOreKhq3bAaitb2Dq3CqAdgsGhYKISDYqK+GJJxqfmwVhUFqasxZmLKpOBkJCw9btzFhUrVAQEcmJv/8dnnyy8XnnzsFuov33z3krdfUNraq3hUJBRCSTv/0NFi1qfN61K0yeDPvtF1tLfUtLqM0QAH1LS9rtMxQKIiKpXnwRnn668XlJSXBq6b77xtdTaMqI8rRjCgAlXToxZUT7TbyjUBCRNov6TJic+stfYMmSxuf77APf/W5wnycS67Zgzz4ys6uASwAD7nb335jZgcAjwEBgFXCOu683MwNuBUYBG4GL3P3lKPsTkbbLxZkwOfHcc8EtYb/9guEo9t47ro5aNGZIWaTrN7JQMLPPEgTCccAW4Ckz+1NYW+Lu08zsWuBa4BpgJDA4vH0JuDO8F5E8lIszYSLjDs8+Cy+80Fg74AC45BLYa6/4+soDUW4pfAZY6u4bAczseeBbwGjgxHCZ+4HnCEJhNDDb3R1YamalZtbH3ddE2KOItFEuzoRpd+7w5z8Hxw0SuncPhrAuab+DtYUsylB4Hfi5mXUHGgh2C1UCvRP/oXf3NWaWGBikDHgn5f01YS0tFMxsEjAJYECeTEohUoxycSZMu3EPziRaurSx1qtXMLlNt27x9ZWHIgsFd3/TzKYDTwOfAK8C21p4i2X6Mxn+7kxgJkBFRUWT10UkN3JxJsxuc4eFC4NrDRIOOiiY9rJr1/j6ymORHmh291nALAAzu4ng1/97id1CZtYHWBsuXgP0T3l7P6Auyv5EpO1ycSZMm7kHVx8vW9ZYKyuD8eNhzz3j66sARH32US93X2tmA4AzgS8Dg4DxwLTwfn64+ALgcjN7mOAA8wYdTxDJb1GfCdNq7sG4RMuXN9b694cLL4QuXeLrq4BEfZ3CH8NjCluByeGpp9OAR81sIrAaODtc9kmC4w4rCE5JnRBxbyLSUezYAfPmwWuvNdYGDoTzz1cYtFLUu4++lqH2ATA8Q92ByVH2IyIdzI4dMHcuvP56Y+2QQ+C884IxiqTVtNZEpPBs3w6PPRZMfZkweDCMHZuXYVBIV37n39oTEWnO9u3w6KNQXd1YKy+Hc86BTp3i66sFhXblt0JBRPLftm3w8MOwYkVj7cgj4ayz8jYMEgrtym+Fgojkr23b4A9/gJUrG2uf/SyceSbssUd8fbVCoV35rVAQkfyzdSv8/vfw73831o45BkaPLpgwSCioK79RKIhIPtmyBWbPhpqaxtqQIXDGGcH0lwWoIK78TqFQEJH4bdkC990HdSmDGFRUwOmnF2wYJOT1ld8ZKBREJD6bN8O998J77zXWjjsORo4s+DBIlXdXfrdAoSAiubdpE8yaBevWNda+/GX4+tc7VBgUIoWCiOROQwPcfTd8+GFj7YQT4JRTFAZ5QqEgItHbuBFmzoT6+sba0KFw0kkKgzyjUBCR6Hz6Kdx1F3z8cWPtxBODm+QlhYKItL9PPoE77wxCIWH4cPhakzEyJc8oFESk/Xz8MdxxR3DsIOHUU4PjBlIQFAoisvs++ghuvz243iBhxIjgjCIpKAoFkWYU0nDHsVm9OrjOINWoUcG1BlKQFAoiGRTacMc5t2pVcAVyKoVBh6BQEMmg0IY7zpm334YHHkivDRgAF18cTz/S7hQKIhkU2nDHkXvrLXjwwfTaIYfAhRfG049ERqEgkkGhDXccmX/+M5jcJtXhhwdzIEuHpFAQyaDQhjtud2+8AXPmpNeOPDKY9lI6NIWCSAaFNtxxu3ntNZg7N732uc8FM51JUVAoiDSjkIY73m3Ll8P8+em1Y48NJreRoqJQEClmlZXwxBPpteOOC04vlaKkUBApRkuXwlNPpde+8pVgPgMpagoFkWLy4ovw9NPptaFD4eST4+lH8k6koWBmPwC+AzhQBUwA+gAPAwcCLwMXuPsWM+sKzAa+AHwAjHX3VVH2J1I0nn8enn02vXbSSTBsWDz9SN6KLBTMrAy4EjjS3RvM7FFgHDAK+LW7P2xmdwETgTvD+/XufpiZjQOmA2Oj6k+kKDzzDLzwQnpNo5ZKC6LefdQZKDGzrcBewBrgZCBx5cv9wA0EoTA6fAzwGHC7mZm7e8Q9inQ8ixfDX/+aXjvtNDj++Hj6kYIRWSi4e62Z/QJYDTQAi4FlQL27bwsXqwES5/yVAe+E791mZhuA7sD7qX/XzCYBkwAGDBgQVfsihWnhQnjppfTa6afDF78YTz9ScKLcfXQAwa//QUA9MAcYmWHRxJZApolam2wluPtMYCZARUWFtiJEAP77v2HZsvTa6NEwZEg8/UjBinL30SnA/7j7OgAzmwt8BSg1s87h1kI/oC5cvgboD9SYWWdgf+DDCPsTKXyPPw6vvppeO/PM4CpkkTaIMhRWA8eb2V4Eu4+GA5XAs8C3Cc5AGg8kLqNcED7/W/j6MzqeINKMOXOC8YlSnX02HHVUPP1IhxHlMYWXzOwxgtNOtwHLCXb7/Al42MxuDGuzwrfMAh4wsxUEWwjjoupNpGA99BBUV6fXxo6Fz3wmnn6kw7FC/jFeUVHhlZWVcbchEr3Zs2HlyvTa+efD4MHx9CMFzcyWuXtFptd0RbNIPrv33mAe5FQXXACHHhpPP9LhKRRE8tHvfgdr1qTXLroIBg6MoxspIgoFkXzy29/CunXptYsvDuZBFskBhYJIPvjNb6C+Pr12ySVQViTzOUjeUCiIxGnGDPj00/TapZdCnz7x9CNFT6EgEoebb4bNm9Nrl10GvXvH049ISKEgkks//Sns2JFemzwZevaMpx+RnSgURKLmDj/5SdP6FVdA9+6570ekBQoFkag0FwZXXQUHHJD7fkSyoFAQaW/NhcEPfgD775/7fkRaQaEg0l6aCYMnho/j5hfrqLv5/9K3tIQpI8oZM0Snmkp+UiiI7K4dO4IDyDu7+mrmvbWBqXOraNi6HYDa+gamzq0CUDBIXlIoFKF5y2uZsaiauvoG/XLdHc2FwZQpsPfeAMxY9PdkICQ0bN3OjEXVWueSlxQKRWbe8lr9ct1d27fDz37WtH7NNVBSklaqq2/I+Ceaq4vETaFQZGYsqtYv17batg1uvLFp/dproVu3jG/pW1pCbYYA6FtakmFpkfgpFIqMfrm2QXNhMHUqdO3a4lunjChP2zIDKOnSiSkjytu7S5F2oVAoMvrl2gpbt8LPf960ft11sOeeWf2JxNaXjuFIoVAoFBn9cs1Cc2Fw/fXQpUur/9yYIWUKASkYCoUio1+uLdiyBW66qWn9xz+Gzvq/ihSHrL7pZnZbhvIGoNLd57dvSxI1/XLdyebNwailqbp0CY4Z7LFHPD2JxCTbnz/dgCOAOeHzs4A3gIlmdpK7fz+K5kQitWkTTJuWXttrL7j6aoWBFK1sQ+Ew4GR33wZgZncCi4FTgaqIehOJRkMDTJ+eXtt332BsIoWBFLlsQ6EM2JtglxHh477uvt3MNjf/NpE8snEj3HJLeu2AA+DKK8Esnp5E8ky2oXAL8IqZPQcYMBS4ycz2Bv4cUW8i7ePTT4NpL1P16BFMbqMwEEmTVSi4+ywzexI4jiAUrnP3uvDlKVE1J7JbPv4YfvnL9FqfPjBpksJApBmtOc9uD2Bd+J7DzOwwd38hmrZEdsNHH8GvfpVe69cPJk5UGIjsQranpE4HxhKccZSYYNaBZkPBzMqBR1JKhwD/CcwO6wOBVcA57r7ezAy4FRgFbAQucveXW/FvkWK3YQP8+tfptYED4aKL4uhGpCBlu6UwBih396wPKrt7NfB5ADPrBNQCjwPXAkvcfZqZXRs+vwYYCQwOb18C7gzvRVq2fj3cemt67dBD4YIL4ulHpIBlGworgS5AW880Gg687e7/NrPRwIlh/X7gOYJQGA3MdncHlppZqZn1cfc1bfxM6eg+/BBu2+m6yvJyOPfcePoR6QCyDYWNBGcfLSElGNz9yizfPw54KHzcO/EfendfY2a9wnoZ8E7Ke2rCWloomNkkYBLAgAEDsvx46VDefx9uvz29dtRRcPbZ8fQj0oFkGwoLwlurmdmewBnA1F0tmqHmTQruM4GZABUVFU1elw5s7Vq444702uc+B2eeGU8/Ih1Qtqek3r8bnzESeNnd3wufv5fYLWRmfYC1Yb0G6J/yvn5AHSLvvgt33ZVeO/ZYOOOMePoR6cBaDAUze9TdzzGzKjL/av9cFp9xLo27jiDY4hgPTAvv56fULzezhwkOMG/Q8YQiV1cHM2em1774RTj99Hj6ESkCu9pSuCq8/0Zb/riZ7UUwPtKlKeVpwKNmNhFYDSR2BD9JcDrqCoJjGBPa8pnSAdTUwD33pNe+/GUYMSKefkSKSIuhEO7i6QTMcvdTWvvH3X0j0H2n2gcEZyPtvKwDk1v7GdKBrF4N996bXjvhBDj11Hj6ESlCuzymEA56t9HM9nf3DbtaXqTVVq2C++5Lrw0bBiedFEc3IkUt27OPNgFVZvY08Gmi2IpTUkWaWrkSZs9Or518MgwdGk8/IpJ1KPwpvInsvrfeggcfTK+demqwq0hEYpX1Kanh9QaHh6Vqd98aXVvSIVVXw0MPpddOOw2OPz6efkSkiWwHxDuRYEiKVQQXmfU3s/EaJVWy8uab8Mgj6bXTTw9OLxWRvJLt7qNfAl8PB7nDzA4nuPbgC1E1Jh3A66/DY4+l1775TfiCvjYi+SrbUOiSCAQAd/+XmXWJqCcpdK+9BnPnptfGjIHPfz6efkQka9mGQqWZzQIeCJ+fDyyLpqXiMW95LTMWVVNX30Df0hKmjChnzJCyuNtqu+XLYf789NpZZ8HRR8fTj4i0WrahcBnBhWVXEhxTeAG4o8V3SIvmLa9l6twqGrZuB6C2voGpc6sACi8YKivhiSfSa2efHYxcKiIFJdtQ6Azc6u6/guSkOV0j66oIzFhUnQyEhIat25mxqLpwQuGll2DhwvTauHFwxBHx9CMiuy3bUFgCnAJ8Ej4vARYDX4miqWJQV9/Qqnpe+etfYfHi9Np558Hhh2deXkQKRrah0M3dE4GAu38SDnYnbdS3tITaDAHQt7Qkhm6y9Je/wJIl6bX/+A847LB4+hGRdpdtKHxqZse6+8sAZlYBFMBP2vw1ZUR52jEFgJIunZgyojzGrprx/PPw7LPptfHjYdCgePoRkchkGwpXAXPMrI5gXoW+wNjIuioCieMGeX320TPPwAs7XZ84YQIcfHA8/YhI5LINhUHAEGAA8C3geDJMuiOtM2ZIWX6FQMLixcFxg1QTJ0L//pmXF5EOI9tQ+F/uPsfMSgkmzfklcCfBDGnSUSxcGJxRlOqSS6AsD4NLRCKRbSgkdnyfDtzl7vPN7IZoWpKce+KJ4FqDVJdeCn36xNOPiMQm21CoNbPfEZyWOt3MugJ7RNeW5MS8efDKK+m1yy6D3r3j6UdEYpdtKJwDnAb8wt3rzawPMCW6tiRSN9zQtDZ5MvTsmfNWRCS/ZDufwkZgbsrzNcCaqJqSiGQKgyuugO7dm9ZFpChlu6UghSxTGFx8MQwYkPNWRCS/KRQ6skxhoLOJRKQFCoWOxh1+8pOm9e9+Fw46KPf9iEhBUSh0FM2Fwfe+B7165b4fESlICoVC11wYXH459OiR+35EpKBFGgrhFdD3AJ8lGBbjYqAaeAQYCKwCznH39WZmwK3AKGAjcFFiAD7JoLkwuPJKOPDA3PcjIh1C1FsKtwJPufu3zWxPYC/gOmCJu08zs2uBa4FrgJHA4PD2JTSMRmY7dsBPf9q0/v3vQ2lp7vsRkQ4lslAws/2AocBFAO6+BdhiZqOBE8PF7geeIwiF0cBsd3dgqZmVmlmf8JoI2b4dfvazpvUf/hD22y/3/YhIhxTllsIhwDrgv8zsGGAZwRDcvRP/oXf3NWaWOApaBryT8v6asFbcodBcGFx9NeyzT+77EZEOLcpQ6AwcC1zh7i+Z2a0Eu4qaYxlqTYbnNrNJwCSAAR354qtt2+DGG5vWf/Qj2EuT3olINKIMhRqgxt0TYzE/RhAK7yV2C4VjKK1NWT51wP5+QN3Of9TdZwIzASoqKjrenA5bt8LPf960fs01UJLHU3WKSIcQWSi4+7tm9o6Zlbt7NTAc+H/hbTwwLbyfH75lAXC5mT1McIB5Q1EdT9iyBW66qWl96lTo2jX3/YhIUYr67KMrgAfDM49WAhMIhtx+1MwmAquBs8NlnyQ4HXUFwSmpEyLuLT80t2Vw3XWw556570dEilqkoeDurwAVGV4anmFZByZH2U9eaW7L4PrroUuX3PcjIoKuaM69zZvh5pub1n/8Y+is/zlEJF76r9BumLe8lhmLqqmrb6BvaQlTRpQzZkgzI5Bu2gTTpqXXunULzibaQ5PYiUh+UCi00bzltUydW0XD1mD66tr6BqbOrQJID4aGBpg+Pf3N++wTXHSmMBCRPKNQaKMZi6qTgZDQsHU7MxZVB6GwcSPcckv6m0pL4aqrwDJdkiEiEj+FQhvV1TdkrK9fu77p5DY9egRzICsMRCTPKRTaqG9pCbUpwbDXlgYm/X0u+3brAl8dFBR79w4mt1EYiEiBUCi00ZQR5UydW0WnTz7mO/94HIDOe+zBCYd2h379YOJEhYGIFByFQhuNOWQfjli7mBff/oCPgX27dWHIV4/hiP/9A4WBiBQshUJrrV8Pt94KwBF99uOIPvvBIYfAhRfG3JiIyO5TKGTrww/httvSa4cfDuedF08/IiIRUCjsyvvvw+23p9eOPBLOOSeefkREIqRQaE6mK5CPPhrOOiuefkREckChsLNNm+Cll+DZZxtrQ4bA6NHx9SQikiMKhYSGBli6NAiETZvgiCNg6FDo2zfuzkREckahsHFjYxhs3gyf+QwMGwYHHRR3ZyIiOVe8obBxI/ztb0EYbNkSHDweNiy4CllEpEgVZygsXw4LFwazniXCoFevuLsSEYldcYbCgQcG1xgMGwY9e8bdjYhI3ijOUDj44OAmIiJpNMuLiIgkKRRERCRJoSAiIkkKBRERSVIoiIhIkkJBRESSFAoiIpIUaSiY2SozqzKzV8ysMqwdaGZPm9lb4f0BYd3M7DYzW2Fmr5nZsVH2JiIiTeViS+Ekd/+8u1eEz68Flrj7YGBJ+BxgJDA4vE0C7sxBbyIikiKO3UejgfvDx/cDY1Lqsz2wFCg1sz4x9CciUrSiDgUHFpvZMjObFNZ6u/sagPA+MRJdGfBOyntrwloaM5tkZpVmVrlu3boIWxcRKT5Rj310grvXmVkv4Gkz+2cLy1qGmjcpuM8EZgJUVFQ0eV1ERNou0i0Fd68L79cCjwPHAe8ldguF92vDxWuA/ilv7wfURdmfiIikiywUzGxvM9s38Rj4OvA6sAAYHy42HpgfPl4AXBiehXQ8sCGxm0lERHIjyt1HvYHHzSzxOX9w96fM7B/Ao2Y2EVgNnB0u/yQwClgBbAQmRNibiIhkEFkouPtK4JgM9Q+A4RnqDkyOqh8REdk1XdEsIiJJCgUREUlSKIiISJJCQUREkhQKIiKSpFAQEZGkqIe5KFjzltcyY1E1dfUN9C0tYcqIcsYMaTIUk4hIh6JQyGDe8lqmzq2iYet2AGrrG5g6twpAwSAiHZp2H2UwY1F1MhASGrZuZ8ai6pg6EhHJDYVCBnX1Da2qi4h0FAqFDPqWlrSqLiLSUSgUMpgyopySLp3SaiVdOjFlRHlMHYmI5IYONGeQOJiss49EpNgoFJoxZkiZQkBEio52H4mISJJCQUREkhQKIiKSpFAQEZEkhYKIiCQpFEREJEmhICIiSQoFERFJUiiIiEiSQkFERJIUCiIikqRQEBGRpMgHxDOzTkAlUOvu3zCzQcDDwIHAy8AF7r7FzLoCs4EvAB8AY919VXv3o7mXRUSal4sthauAN1OeTwd+7e6DgfXAxLA+EVjv7ocBvw6Xa1eJuZdr6xtwGudenre8tr0/SkSkIEUaCmbWDzgduCd8bsDJwGPhIvcDY8LHo8PnhK8PD5dvN5p7WUSkZVFvKfwG+BGwI3zeHah3923h8xogse+mDHgHIHx9Q7h8GjObZGaVZla5bt26VjWjuZdFRFoWWSiY2TeAte6+LLWcYVHP4rXGgvtMd69w94qePXu2qifNvSwi0rIotxROAM4ws1UEB5ZPJthyKDWzxAHufkBd+LgG6A8Qvr4/8GF7NqS5l0VEWhZZKLj7VHfv5+4DgXHAM+5+PvAs8O1wsfHA/PDxgvA54evPuHuTLYXdMWZIGTefeTRlpSUYUFZaws1nHq2zj0REQnHM0XwN8LCZ3QgsB2aF9VnAA2a2gmALYVwUH665l0VEmpeTUHD354DnwscrgeMyLLMJODsX/YiISGa6ollERJIUCiIikqRQEBGRJIWCiIgkWTuf9ZlTZrYO+HfcfWSpB/B+3E20gfrOLfWde4Xa++70fbC7Z7z6t6BDoZCYWaW7V8TdR2up79xS37lXqL1H1bd2H4mISJJCQUREkhQKuTMz7gbaSH3nlvrOvULtPZK+dUxBRESStKUgIiJJCgUREUlSKETAzFaZWZWZvWJmlWHtQDN72szeCu8PiLvPnZlZedhz4vaRmX3fzG4ws9qU+qg86PVeM1trZq+n1DKuYwvcZmYrzOw1Mzs2z/qeYWb/DHt73MxKw/pAM2tIWe935VnfzX4vzGxquL6rzWxEPF032/cjKT2vMrNXwno+re/+Zvasmb1pZm+Y2VVhPfrvuLvr1s43YBXQY6faLcC14eNrgelx97mLf0Mn4F3gYOAG4Oq4e9qpv6HAscDru1rHwChgIcHsfscDL+VZ318HOoePp6f0PTB1uTxc3xm/F8CRwKtAV2AQ8DbQKV/63un1XwL/mYfruw9wbPh4X+Bf4XqN/DuuLYXcGQ3cHz6+HxgTYy/ZGA687e55ecW4u79A05n5mlvHo4HZHlhKMPtfn9x0mi5T3+6+2BvnLV9KMCNhXmlmfTdnNPCwu2929/8BVpBhuPxcaKlvMzPgHOChnDaVBXdf4+4vh48/Bt4kmMc+8u+4QiEaDiw2s2VmNims9Xb3NRD8Dw70iq277Iwj/f8sl4ebpffm466vUHPruAx4J2W5mrCWjy4m+MWXMMjMlpvZ82b2tbiaakGm70WhrO+vAe+5+1sptbxb32Y2EBgCvEQOvuMKhWic4O7HAiOByWY2NO6GWsPM9gTOAOaEpTuBQ4HPA2sINrkLiWWo5d252GZ2PbANeDAsrQEGuPsQ4IfAH8xsv7j6y6C570VBrG/gXNJ/+OTd+jazfYA/At93949aWjRDrU3rXKEQAXevC+/XAo8TbDq/l9icC+/XxtfhLo0EXnb39wDc/T133+7uO4C7iWlXQBaaW8c1QP+U5foBdTnurUVmNh74BnC+hzuJw90vH4SPlxHsmz88vi7TtfC9KIT13Rk4E3gkUcu39W1mXQgC4UF3nxuWI/+OKxTamZntbWb7Jh4THER8HVgAjA8XGw/Mj6fDrKT9gtpp3+S3CP49+ai5dbwAuDA8Q+N4YENiEzwfmNlpBHOXn+HuG1PqPc2sU/j4EGAwsDKeLptq4XuxABhnZl3NbBBB33/PdX+7cArwT3evSRTyaX2HxztmAW+6+69SXor+Ox73UfaOdgMOITjz4lXgDeD6sN4dWAK8Fd4fGHevzfS/F/ABsH9K7QGgCngt/PL1yYM+HyLY3N9K8CtpYnPrmGDT+rcEv/yqgIo863sFwf7gV8LbXeGyZ4XfoVeBl4Fv5lnfzX4vgOvD9V0NjMynvsP6fcB3d1o2n9b3Vwl2/7yW8r0YlYvvuIa5EBGRJO0+EhGRJIWCiIgkKRRERCRJoSAiIkkKBRERSVIoiLQTM7vPzL4ddx8iu0OhIBKT8KpakbyiL6VIC8Kr0h8lGDagE/AzoBz4JlAC/BW41He64MfM/jPTMmb2XPj8BOAZM7sIONzdt4bj7LwGDHb3rTn454k0oS0FkZadBtS5+zHu/lngKeB2d/9i+LyEYMyinbW0TKm7D3P3nwDPAaeH9XHAHxUIEieFgkjLqoBTzGy6mX3N3TcAJ5nZS2ZWBZwMHJXhfS0t80jK43uACeHjCcB/tf8/QSR72n0k0gJ3/5eZfYFg3JmbzWwxMJlgbPU5qrMAAAC+SURBVJl3zOwGoFvqe8ysG3BHC8t8mvL3XwyngRxGMDtZvg42KEVCWwoiLTCzvsBGd/898AuCqR0B3g/Hus90tlG3LJZJNZtg4DZtJUjstKUg0rKjgRlmtoNgpM3LCKZArCKYi/sfO7/B3evN7O6WltnJg8CN5OG0kFJ8NEqqSMzCaxtGu/sFcfcioi0FkRiZ2f8hmOluVNy9iIC2FEREJIUONIuISJJCQUREkhQKIiKSpFAQEZEkhYKIiCT9f+Ad/uq/GTNmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ox = x\n",
    "oy = b0 + b1 * ox\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(ox, oy, color='red', alpha=0.5)\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('scoring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Посчитаем коэффициент детерминации и среднюю ошибку аппроксимации.\n",
    "\n",
    "Для этого посчитаем предсказанные значения скорингового балла по данным из зарплат и посчитанных выше коэффициентов линейной регрессии. Коэффициент детерминации имеет в общем виде следующую формулу: $R^2 = \\dfrac{D_{model}}{D_y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: [401 574 874 919 459]\n",
      "pred: [535.89621821 562.10160703 942.07974498 968.2851338  548.99891262]\n"
     ]
    }
   ],
   "source": [
    "z = b0 + b1 * x\n",
    "\n",
    "print(f'real: {y[:5]}')\n",
    "print(f'pred: {z[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876386635293678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2 = z.var() / y.var()\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя ошибка аппроксимации вычисляется по формуле: $\\overline{A} = \\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} \\Bigl| {{\\frac{y_i - z_i}{y_i}} \\Bigr|}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11469251843561709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mean = np.abs((y - z) / y).mean()\n",
    "a_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. F-критерий Фишера используется для оценки статистической значимости уравнения линейной регрессии и имеет формулу $T = \\dfrac{R^2}{1 - R^2} \\cdot \\dfrac{n - k - 1}{k}$\n",
    "\n",
    "R2 мы считали ранее, k1=1, k2=8. Подставим все в формулу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.67164085966437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 8\n",
    "\n",
    "T = (R2 / (1 - R2)) * (k2 / k1)\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем уровень значимости $\\alpha = 0.05$ и посчитаем критическое значение $F_{crit} = F(1, 8)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.317655071578714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "F_crit = stats.f.ppf(1 - alpha, k1, k2)\n",
    "F_crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. $T > F_{crit}$, то уравнение линейной регресси статистически значимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Построим для коэффициентов регрессии доверительные интервалы с помощью t-статистики Стьюдента.\n",
    "\n",
    "Сначала построим доверительный интервал для коэффициента $b_0$. Для этого найдем стандартную ошибку коэффициента наклона $S_{slope} = \\sqrt{\\dfrac{\\frac{1}{n - 2} \\displaystyle\\sum_{i=1}^{n}(y_i - z_i)^2}{\\displaystyle\\sum_{i=1}^n (x_i - \\overline{x})^2}}.$ Значение статистики будет $T = \\dfrac{\\hat{b}_1 - b_1}{S_{slope}}$, где $\\hat{b}_1$ расчетный коэффициент наклона, а $b_1$ - реальный. Требуемый нам уроень доверия можно записать следуюзей формулой: $P \\left( \\hat{b}_1 - t_{1 - \\alpha/2, \\: n - 2} \\cdot S_{slope} \\leq b_1 \\leq \\hat{b}_1 + t_{1 - \\alpha/2, \\: n - 2} \\cdot S_{slope} \\right) = p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_slope(x, y, z):\n",
    "    n = x.shape[0]\n",
    "    upper = ((y - z) ** 2).sum() / (n - 2)\n",
    "    lower = ((x - x.mean()) ** 2).sum()\n",
    "    return np.sqrt(upper / lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48108279568516005"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_slope = standard_error_slope(x, y, z)\n",
    "s_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем $\\alpha = 0.05$ и посчитаем квантиль $t_{1 - \\alpha/2, \\: n - 2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3060041350333704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = x.shape[0]\n",
    "t = stats.t.ppf(1- alpha / 2, df = n - 2)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доверительный интервал для параметра $b_1$ будет равен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5111599662593718, 3.729917798546158)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b1 - t * s_slope, b1 + t *  s_slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для коэффициента $b_0$ нам надо посчитать стандартную ошибку коэффициента сдвига: $S_{intercept} = S_{slope} \\cdot \\sqrt{\\dfrac{1}{n} \\displaystyle\\sum_{i=1}^n x_i^2}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_intercept(x, y, z):\n",
    "    return standard_error_slope(x, y, z) * np.sqrt((x ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.46649755068153"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_intercept = standard_error_intercept(x, y, z)\n",
    "s_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доверительный интервал для $b_0$ будет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313.9653804816363, 574.3893341670829)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b0 - t * s_intercept, b0 + t * s_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "Посчитать коэффициенты линейной регрессии для т.н. Квартета Энскомба.\n",
    "\n",
    "Загрузим датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.74</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.74</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.81</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.81</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.39</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1     y1    x2    y2    x3     y3    x4     y4\n",
       "id                                                   \n",
       "0   10.0   8.04  10.0  9.14  10.0   7.46   8.0   6.58\n",
       "1    8.0   6.95   8.0  8.14   8.0   6.77   8.0   5.76\n",
       "2   13.0   7.58  13.0  8.74  13.0  12.74   8.0   7.71\n",
       "3    9.0   8.81   9.0  8.77   9.0   7.11   8.0   8.84\n",
       "4   11.0   8.33  11.0  9.26  11.0   7.81   8.0   8.47\n",
       "5   14.0   9.96  14.0  8.10  14.0   8.84   8.0   7.04\n",
       "6    6.0   7.24   6.0  6.13   6.0   6.08   8.0   5.25\n",
       "7    4.0   4.26   4.0  3.10   4.0   5.39  19.0  12.50\n",
       "8   12.0  10.84  12.0  9.13  12.0   8.15   8.0   5.56\n",
       "9    7.0   4.82   7.0  7.26   7.0   6.42   8.0   7.91\n",
       "10   5.0   5.68   5.0  4.74   5.0   5.73   8.0   6.89"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anscombe_dataset = pd.read_csv('anscombe_dataset.csv', index_col='id')\n",
    "\n",
    "anscombe_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой пары $x_i, y_i$ найдем коэффициенты $b_{0i}, b_{1i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0000909090909245 0.5000909090909076\n",
      "3.0009090909090768 0.5000000000000014\n",
      "3.0024545454545555 0.4997272727272716\n",
      "3.0017272727272726 0.49990909090909097\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    x = anscombe_dataset[f'x{i}'].values\n",
    "    y = anscombe_dataset[f'y{i}'].values\n",
    "    b1 = ((x * y).mean() - x.mean() * y.mean()) / ((x ** 2).mean() - x.mean() ** 2)\n",
    "    b0 = y.mean() - b1 * x.mean()\n",
    "    print(b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что для каждого из набора, входящего в Квартет Энскомба, коэффициенты линейной регрессии $b_0$ и $b_1$ примерно равны."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
